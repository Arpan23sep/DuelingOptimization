% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/beta_Normalized_Gradient.R
\name{beta_NGD}
\alias{beta_NGD}
\title{Normalized Gradient Descent with Preference Feedback}
\usage{
beta_NGD(initial_point, eta, gamma, T)
}
\arguments{
\item{initial_point}{A numeric vector representing the d-dimensional initial point.}

\item{eta}{A numeric value representing the learning rate (step size) to control the update size at each iteration.}

\item{gamma}{A numeric value representing the perturbation parameter, used to generate nearby points
to probe the function's landscape.}

\item{T}{An integer representing the maximum number of steps the algorithm will take.}
}
\value{
A numeric vector representing the best point found after \code{T} iterations.
}
\description{
Implements a normalized gradient descent algorithm based on preference (dueling) feedback.
The function attempts to find an optimal point in a given space by iteratively updating
the initial point in the direction estimated from comparison feedback.
}
\examples{
initial_point <- c(1, 1)
eta <- 0.01
gamma <- 0.1
T <- 100
result <- beta_NGD(initial_point, eta, gamma, T)
print(result)
}
