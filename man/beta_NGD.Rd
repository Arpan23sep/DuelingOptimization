% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/beta_Normalized_Gradient.R
\name{beta_NGD}
\alias{beta_NGD}
\title{Normalized Gradient Descent with Preference Feedback}
\usage{
beta_NGD(initial_point, eta, gamma, T, f)
}
\arguments{
\item{initial_point}{A numeric vector representing the d-dimensional initial point.}

\item{eta}{A numeric value representing the learning rate (step size) to control the update size at each iteration.}

\item{gamma}{A numeric value representing the perturbation parameter, used to generate nearby points
to probe the function's landscape.}

\item{T}{An integer representing the maximum number of steps the algorithm will take.}

\item{f}{A function representing the objective function to be minimized. This function
must take a numeric vector as input and return a numeric value.}
}
\value{
A list with the following components:
\item{optimum}{A numeric vector representing the best point found after \code{T} iterations.}
\item{f_array}{A numeric vector containing the best function value observed at each iteration.}
}
\description{
Implements a normalized gradient descent algorithm based on preference (dueling) feedback.
The function attempts to find an optimal point in a given space by iteratively updating
the initial point in the direction estimated from comparison feedback.
}
\examples{
f <- function(x) sum(x^2)  # Example quadratic function
initial_point <- c(1, 1)
eta <- 0.01
gamma <- 0.1
T <- 100
result <- beta_NGD(initial_point, eta, gamma, T, f)
print(result)
print(result$f_array)
}
