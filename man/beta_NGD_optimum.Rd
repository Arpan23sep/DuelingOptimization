% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/beta_Normalized_Gradient.R
\name{beta_NGD_optimum}
\alias{beta_NGD_optimum}
\title{Optimized Normalized Gradient Descent with Parameter Tuning}
\usage{
beta_NGD_optimum(initial_point, D, eigen_max, epsilon = 0.1, f)
}
\arguments{
\item{initial_point}{A numeric vector representing the d-dimensional initial point.}

\item{D}{A numeric value representing the diameter of the search space.}

\item{eigen_max}{A numeric value representing the maximum eigenvalue of the Hessian (smoothness parameter).}

\item{epsilon}{A numeric value representing the desired optimization accuracy.}

\item{f}{A function representing the objective function to be minimized. This function
must take a numeric vector as input and return a numeric value.}
}
\value{
A list with the following components:
\item{optimum}{A numeric vector representing the best point found.}
\item{f_array}{A numeric vector containing the best function value observed at each iteration.}
}
\description{
Computes the parameters for normalized gradient descent based on the strong convexity
and smoothness properties of the objective function.
}
\examples{
f <- function(x) sum(x^2)  # Example quadratic function
initial_point <- c(1, 1)
D <- 10
eigen_max <- 5
epsilon <- 0.1
result <- beta_NGD_optimum(initial_point, D, eigen_max, epsilon, f)
print(result$optimum)
print(result$f_array)
}
